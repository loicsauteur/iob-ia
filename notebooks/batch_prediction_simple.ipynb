{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61ee3260-e58f-47e8-9475-51c46d9d2352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Welcome to CellposeSAM, cellpose v\n",
      "cellpose version: \t4.0.6 \n",
      "platform:       \twin32 \n",
      "python version: \t3.11.13 \n",
      "torch version:  \t2.7.1+cu118! The neural network component of\n",
      "CPSAM is much larger than in previous versions and CPU excution is slow. \n",
      "We encourage users to use GPU/MPS if available. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "from cellpose import core, models\n",
    "from cellpose.io import logger_setup\n",
    "from tifffile.tifffile import imread, imwrite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ae43b9d-0340-4dcb-b6aa-d7f5ea41d118",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Organoid 1/*.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "546ae85a-d061-4361-8447-66549f570dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-07 17:10:48,711 [INFO] WRITING LOG OUTPUT TO C:\\Users\\sautlo01\\.cellpose\\run.log\n",
      "2025-07-07 17:10:48,714 [INFO] \n",
      "cellpose version: \t4.0.6 \n",
      "platform:       \twin32 \n",
      "python version: \t3.11.13 \n",
      "torch version:  \t2.7.1+cu118\n",
      "2025-07-07 17:10:48,717 [WARNING] model_type argument is not used in v4.0.1+. Ignoring this argument...\n",
      "2025-07-07 17:10:48,719 [INFO] ** TORCH CUDA version installed and working. **\n",
      "2025-07-07 17:10:48,721 [INFO] >>>> using GPU (CUDA)\n",
      "2025-07-07 17:10:51,216 [INFO] >>>> loading model C:\\Users\\sautlo01\\.cellpose\\models\\cpsam\n"
     ]
    }
   ],
   "source": [
    "use_gpu = core.use_gpu()\n",
    "logger_setup()\n",
    "channels = [0,0]\n",
    "model = models.CellposeModel(gpu=use_gpu, model_type='cpsam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "629f551e-7a2c-4f22-b997-770e406881e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Organoid 1\\20250520_10x_Nq145um-C1.tif\n",
      "2025-07-07 17:13:33,794 [WARNING] channels deprecated in v4.0.1+. If data contain more than 3 channels, only the first 3 channels will be used\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "z_axis must be specified when segmenting 3D images of ndim=3",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m img = imread(p)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mProcessing:\u001b[39m\u001b[33m'\u001b[39m, p)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m masks, _, _ , _ = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdiameter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdo_3D\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m imwrite(p.replace(\u001b[33m'\u001b[39m\u001b[33m.tif\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m__cp-mask.tif\u001b[39m\u001b[33m'\u001b[39m), mask)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m    >mask saved\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mS:\\anaconda_envs\\cellpose4x\\Lib\\site-packages\\cellpose\\models.py:262\u001b[39m, in \u001b[36mCellposeModel.eval\u001b[39m\u001b[34m(self, x, batch_size, resample, channels, channel_axis, z_axis, normalize, invert, rescale, diameter, flow_threshold, cellprob_threshold, do_3D, anisotropy, flow3D_smooth, stitch_threshold, min_size, max_size_fraction, niter, augment, tile_overlap, bsize, compute_masks, progress)\u001b[39m\n\u001b[32m    258\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m masks, flows, styles\n\u001b[32m    260\u001b[39m \u001b[38;5;66;03m############# actual eval code ############\u001b[39;00m\n\u001b[32m    261\u001b[39m \u001b[38;5;66;03m# reshape image\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m x = \u001b[43mtransforms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mz_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mz_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mdo_3D\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo_3D\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstitch_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[38;5;66;03m# Add batch dimension if not present\u001b[39;00m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.ndim < \u001b[32m4\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mS:\\anaconda_envs\\cellpose4x\\Lib\\site-packages\\cellpose\\transforms.py:580\u001b[39m, in \u001b[36mconvert_image\u001b[39m\u001b[34m(x, channel_axis, z_axis, do_3D)\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;66;03m# make sure that channel_axis and z_axis are specified if 3D\u001b[39;00m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m do_3D:\n\u001b[32m--> \u001b[39m\u001b[32m580\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_image_3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mz_axis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[38;5;66;03m######################## 2D reshaping ########################\u001b[39;00m\n\u001b[32m    583\u001b[39m \u001b[38;5;66;03m# if user specifies channel axis, return early\u001b[39;00m\n\u001b[32m    584\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m channel_axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mS:\\anaconda_envs\\cellpose4x\\Lib\\site-packages\\cellpose\\transforms.py:492\u001b[39m, in \u001b[36m_convert_image_3d\u001b[39m\u001b[34m(x, channel_axis, z_axis)\u001b[39m\n\u001b[32m    490\u001b[39m     channel_axis = \u001b[32m3\u001b[39m\n\u001b[32m    491\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m x.ndim == \u001b[32m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m z_axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mz_axis must be specified when segmenting 3D images of ndim=3\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m channel_axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m z_axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    496\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFor 4D images, both `channel_axis` and `z_axis` must be explicitly specified. Please provide values for both parameters.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: z_axis must be specified when segmenting 3D images of ndim=3"
     ]
    }
   ],
   "source": [
    "for p in glob(path):\n",
    "    if '-C' in p:\n",
    "        img = imread(p)\n",
    "        print('Processing:', p)\n",
    "\n",
    "        masks, _, _ , _ = model.eval(\n",
    "            img, channels=channels,\n",
    "            diameter=15,\n",
    "            do_3D=True,\n",
    "            z_axis=0,\n",
    "        )\n",
    "\n",
    "        imwrite(p.replace('.tif', '__cp-mask.tif'), masks)\n",
    "        print('    >mask saved')\n",
    "        del img\n",
    "        del masks\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479d3298-a81b-4282-bc2c-9c37aa671035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
